{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b09941",
   "metadata": {},
   "source": [
    "# Tutorial: Training a GNN Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9af1c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowledge_algorithms.knowledge_graph.neo4j import Neo4jAPI\n",
    "from talent_recommendation.BipartiteRecSys import load_configs, rec_sys_train, HeteroGNN\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.transforms import ToUndirected, RandomLinkSplit\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62450fa9",
   "metadata": {},
   "source": [
    "The essential configurations are all listed in `./talent_recommendation/configs.yaml`. Feel free to modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd01d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = \"./talent_recommendation/configs.yaml\"\n",
    "configs = load_configs(configs, check_keys=[\"neo4j\"])\n",
    "\n",
    "configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0beb6d3",
   "metadata": {},
   "source": [
    "Run the following steps if you want to train a recommendation model in ONE STEP.\n",
    "\n",
    "```python\n",
    "model, data = rec_sys_train(configs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc551d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import HeteroConv, RGCNConv, SAGEConv\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d265b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Neo4jAPI(configs[\"neo4j\"][\"url\"], configs[\"neo4j\"][\"user\"], configs[\"neo4j\"][\"password\"])\n",
    "\n",
    "data = db.load_hetero_graph_dataset([\"employee\", \"project\", \"position\", \"techStack\"])\n",
    "data.metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c25fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hetero_conv_layer(in_channels, out_channels, data: HeteroData, conv_layer=SAGEConv, aggr=\"sum\"):\n",
    "    if conv_layer == RGCNConv:\n",
    "        return HeteroConv({\n",
    "            edge_type: conv_layer(in_channels, out_channels, 1) for edge_type in data.edge_types\n",
    "        }, aggr=aggr)\n",
    "    else:\n",
    "        return HeteroConv({\n",
    "            edge_type: conv_layer(in_channels, out_channels, num_relations=1, add_self_loops=False) for edge_type in data.edge_types\n",
    "        }, aggr=aggr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9b9add",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, out_channels, data: HeteroData, num_conv_layers=3, \n",
    "                 conv_layer=RGCNConv):\n",
    "        super().__init__()\n",
    "\n",
    "        assert(num_conv_layers >= 2)\n",
    "        \n",
    "        self.conv_layer_list = torch.nn.ModuleList()\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "\n",
    "        # Define the first convolutional layer\n",
    "        conv1 = get_hetero_conv_layer(input_channels, hidden_channels, data, conv_layer)\n",
    "        self.conv_layer_list.append(conv1)\n",
    "        \n",
    "        # Define the middle convolutional layers\n",
    "        for _ in range(num_conv_layers-2):\n",
    "            self.conv_layer_list.append(get_hetero_conv_layer(hidden_channels, hidden_channels, data))\n",
    "\n",
    "        # Define the third convolutional layer\n",
    "        self.conv_layer_list.append(get_hetero_conv_layer(hidden_channels, out_channels, data))\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        for i in range(self.num_conv_layers - 1):\n",
    "            x_dict = self.conv_layer_list[i](x_dict, edge_index_dict)\n",
    "            x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "\n",
    "        # Final layer\n",
    "        x_dict = self.conv_layer_list[-1](x_dict, edge_index_dict)\n",
    "\n",
    "        return x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440ca9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 768  # Feature size of your nodes\n",
    "hidden_channels = 128 # Example size, adjust as needed\n",
    "out_channels = 64     # Example size, adjust as needed\n",
    "\n",
    "def transform_hetero_data_for_rec_sys(data, to_undirected=True, random_data_split=True):\n",
    "    if to_undirected:\n",
    "        data = ToUndirected()(data)\n",
    "    if random_data_split:\n",
    "        transform = RandomLinkSplit(\n",
    "            num_val=0.1,\n",
    "            num_test=0.0,\n",
    "            is_undirected=True,\n",
    "            neg_sampling_ratio=0.0,\n",
    "            edge_types=[(\"employee\", \"workedIn\", \"project\")],\n",
    "            rev_edge_types=[(\"project\", \"rev_workedIn\", \"employee\")]\n",
    "        )\n",
    "        train_data, val_data, test_data = transform(data)\n",
    "        return train_data, val_data, test_data\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "model = HeteroGNN(input_channels, hidden_channels, out_channels, data, conv_layer=SAGEConv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd728d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_samples(pos_edge_index, num_nodes, num_neg_samples):\n",
    "    \"\"\"\n",
    "    Generate negative samples.\n",
    "\n",
    "    :param pos_edge_index: Tensor of shape [2, num_edges] representing positive edges.\n",
    "    :param num_nodes: Tuple (num_employees, num_projects) - the number of nodes in each category.\n",
    "    :param num_neg_samples: The number of negative samples to generate.\n",
    "    :return: Tensor of negative samples.\n",
    "    \n",
    "\n",
    "    This step is crucial for effectively training your model, \n",
    "    especially since the quality of the negative samples can significantly influence the model's performance.\n",
    "\n",
    "    - Positive Samples:\n",
    "        Positive samples are straightforward since they are the existing edges in your graph. \n",
    "        For instance, if you're recommending projects to employees, \n",
    "        your positive samples are the `('employee', 'workedIn', 'project')` edges.\n",
    "\n",
    "    - Negative Samples:\n",
    "        Generating negative samples is more challenging. \n",
    "        You need to create pairs of nodes that do not have an existing edge between them. \n",
    "        It's important that these negative samples are realistic; \n",
    "        that is, they should be plausible but non-existent edges.\n",
    "\n",
    "    Here's a simple approach to generate negative samples:\n",
    "    \n",
    "        1. Randomly select an 'employee' node.\n",
    "        2. Randomly select a 'project' or 'position' node.\n",
    "        3. Check if this pair forms an edge in your graph. If not, it's a valid negative sample.\n",
    "        4. Repeat this process until you have the desired number of negative samples.\n",
    "    \n",
    "    \n",
    "    *Examples:*\n",
    "     \n",
    "    ```python\n",
    "    # Example usage\n",
    "    num_employees = 10000\n",
    "    num_projects = 4371  # or num_positions\n",
    "    num_neg_samples = 10000  # This can be adjusted\n",
    "\n",
    "    # Assuming you have your positive edge index for ('employee', 'workedIn', 'project')\n",
    "    pos_edge_index = data[('employee', 'workedIn', 'project')].edge_index\n",
    "    neg_edge_index = generate_negative_samples(pos_edge_index, (num_employees, num_projects), num_neg_samples)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    neg_samples = []\n",
    "    while len(neg_samples) < num_neg_samples:\n",
    "        # Randomly select an 'employee' and a 'project/position'\n",
    "        employee = random.randint(0, num_nodes[0] - 1)\n",
    "        project = random.randint(0, num_nodes[1] - 1)\n",
    "\n",
    "        # Check if this is a negative sample\n",
    "        if not torch.any((pos_edge_index[0] == employee) & (pos_edge_index[1] == project)):\n",
    "            neg_samples.append([employee, project])\n",
    "\n",
    "    return torch.tensor(neg_samples).t().to(pos_edge_index.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735e819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def compute_auc(pos_scores, neg_scores):\n",
    "    labels = torch.cat([torch.ones(pos_scores.size(0)), torch.zeros(neg_scores.size(0))])\n",
    "    scores = torch.cat([pos_scores, neg_scores])\n",
    "    return roc_auc_score(labels.detach().cpu(), scores.detach().cpu())\n",
    "\n",
    "def compute_precision_recall_f1(pos_scores, neg_scores, threshold=0.5):\n",
    "    scores = torch.cat([pos_scores, neg_scores])\n",
    "    predictions = (scores > threshold).float()\n",
    "    labels = torch.cat([torch.ones(pos_scores.size(0)), torch.zeros(neg_scores.size(0))])\n",
    "    \n",
    "    precision = precision_score(labels.detach().cpu(), predictions.detach().cpu())\n",
    "    recall = recall_score(labels.detach().cpu(), predictions.detach().cpu())\n",
    "    f1 = f1_score(labels.detach().cpu(), predictions.detach().cpu())\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "def hit_at_k(pos_scores, neg_scores, k=10):\n",
    "    # Combine scores and sort them\n",
    "    combined_scores = torch.cat([pos_scores, neg_scores])\n",
    "    _, indices = combined_scores.topk(k)\n",
    "\n",
    "    # Calculate hits\n",
    "    hits = (indices < pos_scores.size(0)).float().sum().item()\n",
    "    return hits / k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7db77b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loss function\n",
    "# margin = 0.5\n",
    "# loss_function = torch.nn.MarginRankingLoss(margin=margin)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(model:torch.nn.Module, train_data:HeteroData, val_data:HeteroData=None,\n",
    "          target_edge_type=None, loss_function=\"MarginRankingLoss\", optimizer=\"Adam\", \n",
    "          num_epochs=3, num_neg_samples=None, loss_function_kwargs={\"margin\": 0.5}, \n",
    "          lr=0.001, k_to_hit=5, device=None, val_per_epochs=10):\n",
    "    \n",
    "    h, r, t = target_edge_type\n",
    "    model.train()\n",
    "    \n",
    "    # ensure device\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_data = train_data.to(device)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # loss function\n",
    "    if loss_function == \"MarginRankingLoss\":\n",
    "        loss_function = torch.nn.MarginRankingLoss(**loss_function_kwargs)\n",
    "        \n",
    "    # optimizer\n",
    "    if optimizer == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    if num_neg_samples is None:\n",
    "        num_neg_samples = train_data[target_edge_type].num_edges\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through GNN\n",
    "        node_embeddings = model(train_data.x_dict, train_data.edge_index_dict)\n",
    "\n",
    "        # Assume you have a function to generate positive and negative samples\n",
    "        pos_samples = train_data[target_edge_type].edge_index\n",
    "        neg_samples = generate_negative_samples(\n",
    "            pos_samples, \n",
    "            (train_data[h].num_nodes, train_data[t].num_nodes), \n",
    "            num_neg_samples=num_neg_samples\n",
    "        )\n",
    "\n",
    "        # Compute scores for positive and negative samples\n",
    "        # Example: Using dot product to compute scores\n",
    "        pos_scores = (node_embeddings[h][pos_samples[0]] * node_embeddings[t][pos_samples[1]]).sum(dim=1)\n",
    "        neg_scores = (node_embeddings[h][neg_samples[0]] * node_embeddings[t][neg_samples[1]]).sum(dim=1)\n",
    "\n",
    "        # Target tensor for MarginRankingLoss\n",
    "        target = torch.ones(pos_scores.size(), device=device)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(pos_scores, neg_scores, target)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        if epoch + 1 % val_per_epochs == 0:\n",
    "            if val_data is not None:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    # Compute embeddings for validation set\n",
    "                    val_embeddings = model(val_data.x_dict, val_data.edge_index_dict)\n",
    "\n",
    "                    # Generate positive and negative samples for validation\n",
    "                    val_pos_samples = val_data[target_edge_type].edge_index\n",
    "                    val_neg_samples = generate_negative_samples(\n",
    "                        val_pos_samples,\n",
    "                        (val_data[h].num_nodes, val_data[t].num_nodes),\n",
    "                        num_neg_samples=val_data[target_edge_type].num_edges\n",
    "                    )\n",
    "\n",
    "                    # Compute scores for validation samples\n",
    "                    val_pos_scores = (val_embeddings[h][val_pos_samples[0]] * val_embeddings[t][val_pos_samples[1]]).sum(dim=1)\n",
    "                    val_neg_scores = (val_embeddings[h][val_neg_samples[0]] * val_embeddings[t][val_neg_samples[1]]).sum(dim=1)\n",
    "\n",
    "                    # Calculate metrics\n",
    "                    val_auc = compute_auc(val_pos_scores, val_neg_scores)\n",
    "                    val_precision, val_recall, val_f1 = compute_precision_recall_f1(val_pos_scores, val_neg_scores)\n",
    "                    val_hit_k = hit_at_k(val_pos_scores, val_neg_scores, k=k_to_hit)  # You can adjust k\n",
    "                    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.6f}, \"\n",
    "                        f\"Val AUC: {val_auc:.4f}, Val Precision: {val_precision:.4f}, \"\n",
    "                        f\"Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val Hit@K: {val_hit_k:.4f}\")\n",
    "            else:\n",
    "                print(f\"Epoch [{epoch+1:03d}/{num_epochs}], Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46630f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  employee={ x=[10000, 768] },\n",
       "  project={ x=[4371, 768] },\n",
       "  position={ x=[41, 768] },\n",
       "  techStack={ x=[67, 768] },\n",
       "  (employee, workedIn, project)={\n",
       "    edge_index=[2, 35988],\n",
       "    edge_label=[35988],\n",
       "    edge_label_index=[2, 35988],\n",
       "  },\n",
       "  (employee, workedAs, position)={ edge_index=[2, 38513] },\n",
       "  (employee, hasTechStack, techStack)={ edge_index=[2, 2966] },\n",
       "  (project, needPosition, position)={ edge_index=[2, 35641] },\n",
       "  (project, needTechstack, techStack)={ edge_index=[2, 37316] },\n",
       "  (position, needTechstack, techStack)={ edge_index=[2, 2665] },\n",
       "  (project, rev_workedIn, employee)={ edge_index=[2, 35988] },\n",
       "  (position, rev_workedAs, employee)={ edge_index=[2, 38513] },\n",
       "  (techStack, rev_hasTechStack, employee)={ edge_index=[2, 2966] },\n",
       "  (position, rev_needPosition, project)={ edge_index=[2, 35641] },\n",
       "  (techStack, rev_needTechstack, project)={ edge_index=[2, 37316] },\n",
       "  (techStack, rev_needTechstack, position)={ edge_index=[2, 2665] },\n",
       "  (employee, rev_rev_workedIn, project)={ edge_index=[2, 39986] },\n",
       "  (employee, rev_rev_workedAs, position)={ edge_index=[2, 38513] },\n",
       "  (employee, rev_rev_hasTechStack, techStack)={ edge_index=[2, 2966] },\n",
       "  (project, rev_rev_needPosition, position)={ edge_index=[2, 35641] },\n",
       "  (project, rev_rev_needTechstack, techStack)={ edge_index=[2, 37316] },\n",
       "  (position, rev_rev_needTechstack, techStack)={ edge_index=[2, 2665] }\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.0,\n",
    "    is_undirected=True,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[(\"employee\", \"workedIn\", \"project\")],\n",
    "    rev_edge_types=[(\"project\", \"rev_workedIn\", \"employee\")]\n",
    ")\n",
    "train_data, val_data, test_data = transform(data)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f128c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 2.343534, Val AUC: 0.4826, Val Precision: 0.5003, Val Recall: 0.7036, Val F1: 0.5848, Val Hit@K: 0.0000\n",
      "Epoch [11/100], Loss: 1.890876, Val AUC: 0.5188, Val Precision: 0.7833, Val Recall: 0.0026, Val F1: 0.0052, Val Hit@K: 0.8000\n",
      "Epoch [21/100], Loss: 0.507581, Val AUC: 0.5840, Val Precision: 0.5714, Val Recall: 0.0001, Val F1: 0.0002, Val Hit@K: 0.6000\n",
      "Epoch [31/100], Loss: 0.419804, Val AUC: 0.6302, Val Precision: 0.9273, Val Recall: 0.0014, Val F1: 0.0028, Val Hit@K: 1.0000\n",
      "Epoch [41/100], Loss: 0.367059, Val AUC: 0.6754, Val Precision: 0.8925, Val Recall: 0.0046, Val F1: 0.0092, Val Hit@K: 1.0000\n",
      "Epoch [51/100], Loss: 0.343199, Val AUC: 0.7017, Val Precision: 0.8908, Val Recall: 0.0029, Val F1: 0.0059, Val Hit@K: 1.0000\n",
      "Epoch [61/100], Loss: 0.309591, Val AUC: 0.7357, Val Precision: 0.9302, Val Recall: 0.0011, Val F1: 0.0022, Val Hit@K: 1.0000\n",
      "Epoch [71/100], Loss: 0.281700, Val AUC: 0.7613, Val Precision: 0.9519, Val Recall: 0.0049, Val F1: 0.0098, Val Hit@K: 1.0000\n",
      "Epoch [81/100], Loss: 0.257766, Val AUC: 0.7822, Val Precision: 0.9026, Val Recall: 0.0067, Val F1: 0.0133, Val Hit@K: 1.0000\n",
      "Epoch [91/100], Loss: 0.248914, Val AUC: 0.7908, Val Precision: 0.9433, Val Recall: 0.0093, Val F1: 0.0183, Val Hit@K: 0.8000\n"
     ]
    }
   ],
   "source": [
    "train(model, train_data, val_data, (\"employee\", \"workedIn\", \"project\"), num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c96319f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.to(\"cpu\").state_dict(), \"./checkpoints/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbf50f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db.fetch_data(\"Match (e:employee) return e.name as name ORDER BY e.name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a62cf687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[\"name\"] == \"MT83208\").sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
